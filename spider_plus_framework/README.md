## spider_plus 框架 说明

基于 scrapy 开发的 python 分布式爬虫框架, 实现了 scrapy 的基本功能, 包括以下模块

- 三个内置对象：

  - 请求对象(Request)
  - 响应对象(Response)
  - 数据对象(Item)

- 五个核心组件：

  - 爬虫组件

    - 构建请求信息(初始的)，也就是生成请求对象(Request)
    - 解析响应对象，返回数据对象(Item)或者新的请求对象(Request)

  - 调度器组件

    - 缓存请求对象(Request)，并为下载器提供请求对象，实现请求的调度
    - 对请求对象进行去重判断

  - 下载器组件

    - 根据请求对象(Request)，发起HTTP、HTTPS网络请求，拿到HTTP、HTTPS响应，构建响应对象(Response)并返回

  - 管道组件

    - 负责处理数据对象(Item)

  - 引擎组件

    - 负责驱动各大组件，通过调用各自对外提供的API接口，实现它们之间的交互和协作
    - 提供整个框架的启动入口

- 两个中间件：

  - 爬虫中间件
    - 对请求对象和数据对象进行预处理

  - 下载器中间件
    - 对请求对象和响应对象进行预处理

## 使用方法

参见 spider_project 文件夹

## TODO

- [ ] 添加异常处理模块
- [ ] 添加代理池和cookies池功能
- [ ] 添加爬虫监控组件
- [ ] xpath规则入库, 从数据库提取xpath规则, 方便后期维护
- [ ] 修改爬虫调度器, 实现多个爬虫请求的轮流发送, 以达到反反爬以及最大化使用代理的效果
- [ ] 添加布隆过滤器作为去重方法, 支持亿级请求过滤
- [ ] 添加常用的数据库连接组件, mongodb, mysql, postgresql, redis
